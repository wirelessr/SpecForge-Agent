# Environment Configuration Example
# Copy this file to .env and edit the values for your environment
# 
# The AutoGen Framework uses a three-tier configuration system:
# 1. Environment Variables (this file) - Connection & environment settings
# 2. Config Files (config/*.json) - Behavior & model properties  
# 3. Command Arguments - Execution control
#
# See docs/configuration-guide.md for complete documentation

# =============================================================================
# CONNECTION SETTINGS (Keep in environment variables)
# =============================================================================

# LLM Service Connection
LLM_BASE_URL=http://your-llm-server.local:8888/openai/v1
LLM_MODEL=models/your-model-name
LLM_API_KEY=your-actual-api-key-here

# =============================================================================
# ENVIRONMENT SETTINGS (Keep in environment variables)
# =============================================================================

# Framework Environment
WORKSPACE_PATH=workspace
LOG_LEVEL=INFO

# Configuration File Paths (optional overrides)
CONFIG_DIR=./config
MODELS_CONFIG_FILE=./config/models.json
FRAMEWORK_CONFIG_FILE=./config/framework.json

# =============================================================================
# DEPRECATED SETTINGS (Move to config/framework.json)
# =============================================================================
# The following settings should be moved to config files for better organization:
#
# LLM_TEMPERATURE=0.7                    → config/framework.json: llm.temperature
# LLM_MAX_OUTPUT_TOKENS=4096             → config/framework.json: llm.max_output_tokens  
# LLM_TIMEOUT_SECONDS=60                 → config/framework.json: llm.timeout_seconds
# SHELL_TIMEOUT_SECONDS=30               → config/framework.json: shell.timeout_seconds
# SHELL_MAX_RETRIES=2                    → config/framework.json: shell.max_retries
#
# See docs/migration-guide.md for step-by-step migration instructions

# =============================================================================
# ENVIRONMENT-SPECIFIC EXAMPLES
# =============================================================================

# Development Environment (.env.development)
# LLM_BASE_URL=http://localhost:8888/openai/v1
# LLM_MODEL=models/gemini-2.0-flash
# LLM_API_KEY=sk-dev-key
# LOG_LEVEL=DEBUG
# FRAMEWORK_CONFIG_FILE=config/examples/development.json

# Production Environment (.env.production)  
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-4-turbo
# LLM_API_KEY=sk-prod-key
# LOG_LEVEL=WARNING
# FRAMEWORK_CONFIG_FILE=config/examples/production.json

# Testing Environment (.env.test)
# LLM_BASE_URL=http://test.local:8888/openai/v1
# LLM_MODEL=models/test-model
# LLM_API_KEY=test-key
# LOG_LEVEL=ERROR
# FRAMEWORK_CONFIG_FILE=config/examples/testing.json

# Integration Testing (.env.integration)
# LLM_BASE_URL=http://ctwuhome.local:8888/openai/v1
# LLM_MODEL=models/gemini-2.0-flash
# LLM_API_KEY=sk-your-real-integration-key
# LOG_LEVEL=INFO

# =============================================================================
# USAGE EXAMPLES
# =============================================================================
#
# Basic usage (uses default config files):
#   autogen-framework --request "Create a hello world script"
#
# With execution control arguments:
#   autogen-framework --verbose --auto-approve --request "Task"
#
# With custom config files:
#   autogen-framework --framework-config config/examples/production.json --request "Task"
#
# Environment-specific usage:
#   FRAMEWORK_CONFIG_FILE=config/examples/development.json autogen-framework --request "Task"